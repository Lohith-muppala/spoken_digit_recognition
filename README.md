# spoken_digit_recognition

The spectrogram have the audio files are spectrograms. The model.py file is the main file while the trained_model.h5 folder is an already trained model with 96% accuracy. 

## Information:
A simple audio/speech dataset consisting of recordings of spoken digits in wav files at 8kHz. The recordings are trimmed so that they have near minimal silence at the beginnings and ends.

FSDD is an open dataset, which means it will grow over time as data is contributed. In order to enable reproducibility and accurate citation the dataset is versioned using Zenodo DOI as well as git tags.

### Current status
6 speakers
3,000 recordings (50 of each digit per speaker)
English pronunciations
LINK to the Dataset: https://github.com/Jakobovski/free-spoken-digit-dataset

## Files:
- trained_model.h5 contains the already trained model
- model.py contains the main file
- spectograms.zip contains the spectogram images of the audio files used by the model. 
